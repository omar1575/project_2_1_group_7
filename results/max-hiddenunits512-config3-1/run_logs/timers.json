{
    "name": "root",
    "gauges": {
        "3DBall.Policy.Entropy.mean": {
            "value": 1.389015793800354,
            "min": 1.389015793800354,
            "max": 1.4189382791519165,
            "count": 8
        },
        "3DBall.Policy.Entropy.sum": {
            "value": 16468.171875,
            "min": 16468.171875,
            "max": 17299.6953125,
            "count": 8
        },
        "3DBall.Environment.EpisodeLength.mean": {
            "value": 84.45714285714286,
            "min": 22.612966601178783,
            "max": 84.45714285714286,
            "count": 8
        },
        "3DBall.Environment.EpisodeLength.sum": {
            "value": 11824.0,
            "min": 11503.0,
            "max": 11824.0,
            "count": 8
        },
        "3DBall.Step.mean": {
            "value": 95923.0,
            "min": 11993.0,
            "max": 95923.0,
            "count": 8
        },
        "3DBall.Step.sum": {
            "value": 95923.0,
            "min": 11993.0,
            "max": 95923.0,
            "count": 8
        },
        "3DBall.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.9900870323181152,
            "min": -0.449939101934433,
            "max": 1.9900870323181152,
            "count": 8
        },
        "3DBall.Policy.ExtrinsicValueEstimate.sum": {
            "value": 278.6121826171875,
            "min": -228.56906127929688,
            "max": 296.9949951171875,
            "count": 8
        },
        "3DBall.Environment.CumulativeReward.mean": {
            "value": 7.44285814676966,
            "min": 1.2608267430245408,
            "max": 7.44285814676966,
            "count": 8
        },
        "3DBall.Environment.CumulativeReward.sum": {
            "value": 1042.0001405477524,
            "min": 640.4999854564667,
            "max": 1042.0001405477524,
            "count": 8
        },
        "3DBall.Policy.ExtrinsicReward.mean": {
            "value": 7.44285814676966,
            "min": 1.2608267430245408,
            "max": 7.44285814676966,
            "count": 8
        },
        "3DBall.Policy.ExtrinsicReward.sum": {
            "value": 1042.0001405477524,
            "min": 640.4999854564667,
            "max": 1042.0001405477524,
            "count": 8
        },
        "3DBall.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 8
        },
        "3DBall.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 8
        },
        "3DBall.Losses.PolicyLoss.mean": {
            "value": 0.09591852066169843,
            "min": 0.09538227445221839,
            "max": 0.10725054541579612,
            "count": 7
        },
        "3DBall.Losses.PolicyLoss.sum": {
            "value": 0.09591852066169843,
            "min": 0.09538227445221839,
            "max": 0.10725054541579612,
            "count": 7
        },
        "3DBall.Losses.ValueLoss.mean": {
            "value": 1.8589735832197447,
            "min": 0.23962888694011378,
            "max": 1.8589735832197447,
            "count": 7
        },
        "3DBall.Losses.ValueLoss.sum": {
            "value": 1.8589735832197447,
            "min": 0.23962888694011378,
            "max": 1.8589735832197447,
            "count": 7
        },
        "3DBall.Policy.LearningRate.mean": {
            "value": 4.7550084149999994e-05,
            "min": 4.7550084149999994e-05,
            "max": 0.000263943012019,
            "count": 7
        },
        "3DBall.Policy.LearningRate.sum": {
            "value": 4.7550084149999994e-05,
            "min": 4.7550084149999994e-05,
            "max": 0.000263943012019,
            "count": 7
        },
        "3DBall.Policy.Epsilon.mean": {
            "value": 0.11585000000000002,
            "min": 0.11585000000000002,
            "max": 0.18798099999999998,
            "count": 7
        },
        "3DBall.Policy.Epsilon.sum": {
            "value": 0.11585000000000002,
            "min": 0.11585000000000002,
            "max": 0.18798099999999998,
            "count": 7
        },
        "3DBall.Policy.Beta.mean": {
            "value": 0.00016691499999999998,
            "min": 0.00016691499999999998,
            "max": 0.0008810118999999999,
            "count": 7
        },
        "3DBall.Policy.Beta.sum": {
            "value": 0.00016691499999999998,
            "min": 0.00016691499999999998,
            "max": 0.0008810118999999999,
            "count": 7
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1764520698",
        "python_version": "3.10.11 (main, May  7 2023, 18:05:05) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\maxim\\OneDrive\\Desktop\\maastricht\\Year 2\\project_2_1\\project_2_1_group_7\\.venv\\Scripts\\mlagents-learn Hidden_Units/random_config_3.yaml --run-id=max-hiddenunits512-config3-1 --env=3DBall_environment/UnityEnvironment --no-graphics --force",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.9.0+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1764520990"
    },
    "total": 292.1540492998902,
    "count": 1,
    "self": 0.43244970007799566,
    "children": {
        "run_training.setup": {
            "total": 0.41534429998137057,
            "count": 1,
            "self": 0.41534429998137057
        },
        "TrainerController.start_learning": {
            "total": 291.3062552998308,
            "count": 1,
            "self": 0.5984620144590735,
            "children": {
                "TrainerController._reset_env": {
                    "total": 15.200859399978071,
                    "count": 1,
                    "self": 15.200859399978071
                },
                "TrainerController.advance": {
                    "total": 271.3159226854332,
                    "count": 10627,
                    "self": 0.6438892474398017,
                    "children": {
                        "env_step": {
                            "total": 132.25829011923634,
                            "count": 10627,
                            "self": 111.0706281196326,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 20.80627310811542,
                                    "count": 10627,
                                    "self": 1.8965024105273187,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 18.9097706975881,
                                            "count": 8470,
                                            "self": 18.9097706975881
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.3813888914883137,
                                    "count": 10627,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 271.72913391003385,
                                            "count": 10627,
                                            "is_parallel": true,
                                            "self": 194.3429291031789,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0009818999096751213,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00042099994607269764,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0005608999636024237,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0005608999636024237
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 77.38522290694527,
                                                    "count": 10627,
                                                    "is_parallel": true,
                                                    "self": 2.8776890146546066,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 4.299331293208525,
                                                            "count": 10627,
                                                            "is_parallel": true,
                                                            "self": 4.299331293208525
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 64.33514340268448,
                                                            "count": 10627,
                                                            "is_parallel": true,
                                                            "self": 64.33514340268448
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 5.873059196397662,
                                                            "count": 10627,
                                                            "is_parallel": true,
                                                            "self": 2.3216207993682474,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 3.5514383970294148,
                                                                    "count": 21254,
                                                                    "is_parallel": true,
                                                                    "self": 3.5514383970294148
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 138.41374331875704,
                            "count": 10627,
                            "self": 0.7708222416695207,
                            "children": {
                                "process_trajectory": {
                                    "total": 35.001378376968205,
                                    "count": 10627,
                                    "self": 22.803779977140948,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 12.197598399827257,
                                            "count": 2,
                                            "self": 12.197598399827257
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 102.64154270011932,
                                    "count": 8,
                                    "self": 29.091446393867955,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 73.55009630625136,
                                            "count": 4494,
                                            "self": 73.55009630625136
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.200024366378784e-06,
                    "count": 1,
                    "self": 3.200024366378784e-06
                },
                "TrainerController._save_models": {
                    "total": 4.191007999936119,
                    "count": 1,
                    "self": 0.04663240001536906,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 4.14437559992075,
                            "count": 1,
                            "self": 4.14437559992075
                        }
                    }
                }
            }
        }
    }
}