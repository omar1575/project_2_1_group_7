{
    "name": "root",
    "gauges": {
        "3DBall.Policy.Entropy.mean": {
            "value": 1.4205900430679321,
            "min": 1.4189382791519165,
            "max": 1.422420620918274,
            "count": 4
        },
        "3DBall.Policy.Entropy.sum": {
            "value": 17047.080078125,
            "min": 17000.771484375,
            "max": 17231.5859375,
            "count": 4
        },
        "3DBall.Environment.EpisodeLength.mean": {
            "value": 25.488938053097346,
            "min": 21.734848484848484,
            "max": 25.488938053097346,
            "count": 4
        },
        "3DBall.Environment.EpisodeLength.sum": {
            "value": 11521.0,
            "min": 11476.0,
            "max": 11523.0,
            "count": 4
        },
        "3DBall.Step.mean": {
            "value": 47958.0,
            "min": 11983.0,
            "max": 47958.0,
            "count": 4
        },
        "3DBall.Step.sum": {
            "value": 47958.0,
            "min": 11983.0,
            "max": 47958.0,
            "count": 4
        },
        "3DBall.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.28197312355041504,
            "min": -0.016050070524215698,
            "max": 0.28197312355041504,
            "count": 4
        },
        "3DBall.Policy.ExtrinsicValueEstimate.sum": {
            "value": 127.45185852050781,
            "min": -8.45838737487793,
            "max": 127.45185852050781,
            "count": 4
        },
        "3DBall.Environment.CumulativeReward.mean": {
            "value": 1.5457964046339019,
            "min": 1.1738140141941338,
            "max": 1.5457964046339019,
            "count": 4
        },
        "3DBall.Environment.CumulativeReward.sum": {
            "value": 698.6999748945236,
            "min": 618.5999854803085,
            "max": 698.6999748945236,
            "count": 4
        },
        "3DBall.Policy.ExtrinsicReward.mean": {
            "value": 1.5457964046339019,
            "min": 1.1738140141941338,
            "max": 1.5457964046339019,
            "count": 4
        },
        "3DBall.Policy.ExtrinsicReward.sum": {
            "value": 698.6999748945236,
            "min": 618.5999854803085,
            "max": 698.6999748945236,
            "count": 4
        },
        "3DBall.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 4
        },
        "3DBall.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 4
        },
        "3DBall.Losses.PolicyLoss.mean": {
            "value": 0.12896665363278026,
            "min": 0.12285692859377742,
            "max": 0.12896665363278026,
            "count": 2
        },
        "3DBall.Losses.PolicyLoss.sum": {
            "value": 0.12896665363278026,
            "min": 0.12285692859377742,
            "max": 0.12896665363278026,
            "count": 2
        },
        "3DBall.Losses.ValueLoss.mean": {
            "value": 0.21407162477284813,
            "min": 0.21407162477284813,
            "max": 0.21638181177000124,
            "count": 2
        },
        "3DBall.Losses.ValueLoss.sum": {
            "value": 0.21407162477284813,
            "min": 0.21407162477284813,
            "max": 0.21638181177000124,
            "count": 2
        },
        "3DBall.Policy.LearningRate.mean": {
            "value": 0.00027681720772759994,
            "min": 0.00027681720772759994,
            "max": 0.0002884146038617999,
            "count": 2
        },
        "3DBall.Policy.LearningRate.sum": {
            "value": 0.00027681720772759994,
            "min": 0.00027681720772759994,
            "max": 0.0002884146038617999,
            "count": 2
        },
        "3DBall.Policy.Epsilon.mean": {
            "value": 0.1922724,
            "min": 0.1922724,
            "max": 0.19613819999999998,
            "count": 2
        },
        "3DBall.Policy.Epsilon.sum": {
            "value": 0.1922724,
            "min": 0.1922724,
            "max": 0.19613819999999998,
            "count": 2
        },
        "3DBall.Policy.Beta.mean": {
            "value": 0.0011080415599999999,
            "min": 0.0011080415599999999,
            "max": 0.0011540445799999993,
            "count": 2
        },
        "3DBall.Policy.Beta.sum": {
            "value": 0.0011080415599999999,
            "min": 0.0011080415599999999,
            "max": 0.0011540445799999993,
            "count": 2
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1765120462",
        "python_version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\moebn\\Documents\\University\\Project 2-1\\project_2_1_group_7\\venv\\Scripts\\mlagents-learn Config/training_config.yaml --run-id=run_batch_size40_buffer_size19300_learning_rate0.0003_beta0.0012_epsilon0.2 --time-scale=20 --env=3DBall_environment/UnityEnvironment.exe --no-graphics",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.9.1+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1765120491"
    },
    "total": 28.515604899992468,
    "count": 1,
    "self": 0.1696527000167407,
    "children": {
        "run_training.setup": {
            "total": 0.06993219998548739,
            "count": 1,
            "self": 0.06993219998548739
        },
        "TrainerController.start_learning": {
            "total": 28.27601999999024,
            "count": 1,
            "self": 0.051053901319392025,
            "children": {
                "TrainerController._reset_env": {
                    "total": 3.38780970001244,
                    "count": 1,
                    "self": 3.38780970001244
                },
                "TrainerController.advance": {
                    "total": 24.830131798662478,
                    "count": 5787,
                    "self": 0.048401498672319576,
                    "children": {
                        "env_step": {
                            "total": 14.281441200146219,
                            "count": 5787,
                            "self": 12.780567000270821,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1.4666371007042471,
                                    "count": 5787,
                                    "self": 0.11997440049890429,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1.3466627002053428,
                                            "count": 4179,
                                            "self": 1.3466627002053428
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.034237099171150476,
                                    "count": 5787,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 25.33272339994437,
                                            "count": 5787,
                                            "is_parallel": true,
                                            "self": 15.556457299535396,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0003229999856557697,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00010199999087490141,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0002209999947808683,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0002209999947808683
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 9.77594310042332,
                                                    "count": 5787,
                                                    "is_parallel": true,
                                                    "self": 0.3393512001784984,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 0.507100899820216,
                                                            "count": 5787,
                                                            "is_parallel": true,
                                                            "self": 0.507100899820216
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 8.23139689938398,
                                                            "count": 5787,
                                                            "is_parallel": true,
                                                            "self": 8.23139689938398
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 0.6980941010406241,
                                                            "count": 5787,
                                                            "is_parallel": true,
                                                            "self": 0.2973682002921123,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.4007259007485118,
                                                                    "count": 11574,
                                                                    "is_parallel": true,
                                                                    "self": 0.4007259007485118
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 10.50028909984394,
                            "count": 5787,
                            "self": 0.05387719953432679,
                            "children": {
                                "process_trajectory": {
                                    "total": 2.5270336003159173,
                                    "count": 5787,
                                    "self": 2.3815121003135573,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.14552150000235997,
                                            "count": 1,
                                            "self": 0.14552150000235997
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 7.919378299993696,
                                    "count": 2,
                                    "self": 2.580387699737912,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 5.338990600255784,
                                            "count": 2895,
                                            "self": 5.338990600255784
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.007024599995929748,
                    "count": 1,
                    "self": 9.899988071992993e-06,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.007014700007857755,
                            "count": 1,
                            "self": 0.007014700007857755
                        }
                    }
                }
            }
        }
    }
}