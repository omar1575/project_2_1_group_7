{
    "name": "root",
    "gauges": {
        "3DBall.Policy.Entropy.mean": {
            "value": 1.4153820276260376,
            "min": 1.4153820276260376,
            "max": 1.4189382791519165,
            "count": 4
        },
        "3DBall.Policy.Entropy.sum": {
            "value": 17069.5078125,
            "min": 16994.982421875,
            "max": 17231.5859375,
            "count": 4
        },
        "3DBall.Environment.EpisodeLength.mean": {
            "value": 27.595238095238095,
            "min": 22.373540856031127,
            "max": 27.595238095238095,
            "count": 4
        },
        "3DBall.Environment.EpisodeLength.sum": {
            "value": 11590.0,
            "min": 11500.0,
            "max": 11590.0,
            "count": 4
        },
        "3DBall.Step.mean": {
            "value": 47990.0,
            "min": 11996.0,
            "max": 47990.0,
            "count": 4
        },
        "3DBall.Step.sum": {
            "value": 47990.0,
            "min": 11996.0,
            "max": 47990.0,
            "count": 4
        },
        "3DBall.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.3735195994377136,
            "min": 0.24922513961791992,
            "max": 0.3735195994377136,
            "count": 4
        },
        "3DBall.Policy.ExtrinsicValueEstimate.sum": {
            "value": 156.87823486328125,
            "min": 124.8617935180664,
            "max": 180.00473022460938,
            "count": 4
        },
        "3DBall.Environment.CumulativeReward.mean": {
            "value": 1.759285639013563,
            "min": 1.2384015249694764,
            "max": 1.759285639013563,
            "count": 4
        },
        "3DBall.Environment.CumulativeReward.sum": {
            "value": 738.8999683856964,
            "min": 635.2999823093414,
            "max": 738.8999683856964,
            "count": 4
        },
        "3DBall.Policy.ExtrinsicReward.mean": {
            "value": 1.759285639013563,
            "min": 1.2384015249694764,
            "max": 1.759285639013563,
            "count": 4
        },
        "3DBall.Policy.ExtrinsicReward.sum": {
            "value": 738.8999683856964,
            "min": 635.2999823093414,
            "max": 738.8999683856964,
            "count": 4
        },
        "3DBall.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 4
        },
        "3DBall.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 4
        },
        "3DBall.Losses.PolicyLoss.mean": {
            "value": 0.10836882888279334,
            "min": 0.10836882888279334,
            "max": 0.11139745361624437,
            "count": 3
        },
        "3DBall.Losses.PolicyLoss.sum": {
            "value": 0.10836882888279334,
            "min": 0.10836882888279334,
            "max": 0.11139745361624437,
            "count": 3
        },
        "3DBall.Losses.ValueLoss.mean": {
            "value": 0.3522971228074387,
            "min": 0.3158039631471582,
            "max": 0.5715470233606914,
            "count": 3
        },
        "3DBall.Losses.ValueLoss.sum": {
            "value": 0.3522971228074387,
            "min": 0.3158039631471582,
            "max": 0.5715470233606914,
            "count": 3
        },
        "3DBall.Policy.LearningRate.mean": {
            "value": 9.12846087154e-05,
            "min": 9.12846087154e-05,
            "max": 9.70986029014e-05,
            "count": 3
        },
        "3DBall.Policy.LearningRate.sum": {
            "value": 9.12846087154e-05,
            "min": 9.12846087154e-05,
            "max": 9.70986029014e-05,
            "count": 3
        },
        "3DBall.Policy.Epsilon.mean": {
            "value": 0.23692689999999997,
            "min": 0.23692689999999997,
            "max": 0.24564789999999997,
            "count": 3
        },
        "3DBall.Policy.Epsilon.sum": {
            "value": 0.23692689999999997,
            "min": 0.23692689999999997,
            "max": 0.24564789999999997,
            "count": 3
        },
        "3DBall.Policy.Beta.mean": {
            "value": 0.0010050021400000004,
            "min": 0.0010050021400000004,
            "max": 0.0010683747399999998,
            "count": 3
        },
        "3DBall.Policy.Beta.sum": {
            "value": 0.0010050021400000004,
            "min": 0.0010050021400000004,
            "max": 0.0010683747399999998,
            "count": 3
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1765154051",
        "python_version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\moebn\\Documents\\University\\Project 2-1\\project_2_1_group_7\\venv\\Scripts\\mlagents-learn Config/training_config.yaml --run-id=run_batch_size53_buffer_size14500_learning_rate0.0001_beta0.0011_epsilon0.25 --time-scale=20 --env=3DBall_environment/UnityEnvironment.exe --no-graphics",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.9.1+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1765154081"
    },
    "total": 29.55815180001082,
    "count": 1,
    "self": 0.19960280001396313,
    "children": {
        "run_training.setup": {
            "total": 0.07455489999847487,
            "count": 1,
            "self": 0.07455489999847487
        },
        "TrainerController.start_learning": {
            "total": 29.28399409999838,
            "count": 1,
            "self": 0.04916190027142875,
            "children": {
                "TrainerController._reset_env": {
                    "total": 4.7330414000025485,
                    "count": 1,
                    "self": 4.7330414000025485
                },
                "TrainerController.advance": {
                    "total": 24.49538919972838,
                    "count": 5664,
                    "self": 0.048255898494971916,
                    "children": {
                        "env_step": {
                            "total": 14.222545600845478,
                            "count": 5664,
                            "self": 12.70889710096526,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1.4796582998533268,
                                    "count": 5664,
                                    "self": 0.12062489989330061,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1.3590333999600261,
                                            "count": 4186,
                                            "self": 1.3590333999600261
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.033990200026892126,
                                    "count": 5664,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 25.092584200232523,
                                            "count": 5664,
                                            "is_parallel": true,
                                            "self": 15.363281300640665,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0002727000101003796,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 8.050003089010715e-05,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00019219997921027243,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00019219997921027243
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 9.729030199581757,
                                                    "count": 5664,
                                                    "is_parallel": true,
                                                    "self": 0.3310204983863514,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 0.5147990017721895,
                                                            "count": 5664,
                                                            "is_parallel": true,
                                                            "self": 0.5147990017721895
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 8.228924599592574,
                                                            "count": 5664,
                                                            "is_parallel": true,
                                                            "self": 8.228924599592574
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 0.6542860998306423,
                                                            "count": 5664,
                                                            "is_parallel": true,
                                                            "self": 0.2852426006575115,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.36904349917313084,
                                                                    "count": 11328,
                                                                    "is_parallel": true,
                                                                    "self": 0.36904349917313084
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 10.224587700387929,
                            "count": 5664,
                            "self": 0.05698409996693954,
                            "children": {
                                "process_trajectory": {
                                    "total": 2.5010322004090995,
                                    "count": 5664,
                                    "self": 2.4171092004107777,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.08392299999832176,
                                            "count": 1,
                                            "self": 0.08392299999832176
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 7.66657140001189,
                                    "count": 3,
                                    "self": 2.985863200010499,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 4.680708200001391,
                                            "count": 2460,
                                            "self": 4.680708200001391
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.006401599996024743,
                    "count": 1,
                    "self": 9.799987310543656e-06,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.006391800008714199,
                            "count": 1,
                            "self": 0.006391800008714199
                        }
                    }
                }
            }
        }
    }
}