{
    "name": "root",
    "gauges": {
        "3DBall.Policy.Entropy.mean": {
            "value": 1.4105641841888428,
            "min": 1.4105641841888428,
            "max": 1.418938159942627,
            "count": 4
        },
        "3DBall.Policy.Entropy.sum": {
            "value": 17045.2578125,
            "min": 16995.34765625,
            "max": 17180.50390625,
            "count": 4
        },
        "3DBall.Environment.EpisodeLength.mean": {
            "value": 23.197580645161292,
            "min": 21.734848484848484,
            "max": 23.197580645161292,
            "count": 4
        },
        "3DBall.Environment.EpisodeLength.sum": {
            "value": 11506.0,
            "min": 11476.0,
            "max": 11506.0,
            "count": 4
        },
        "3DBall.Step.mean": {
            "value": 47967.0,
            "min": 11981.0,
            "max": 47967.0,
            "count": 4
        },
        "3DBall.Step.sum": {
            "value": 47967.0,
            "min": 11981.0,
            "max": 47967.0,
            "count": 4
        },
        "3DBall.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.22972765564918518,
            "min": -0.11018452793359756,
            "max": 0.22972765564918518,
            "count": 4
        },
        "3DBall.Policy.ExtrinsicValueEstimate.sum": {
            "value": 113.94491577148438,
            "min": -58.06724548339844,
            "max": 113.94491577148438,
            "count": 4
        },
        "3DBall.Environment.CumulativeReward.mean": {
            "value": 1.3143144605621215,
            "min": 1.1734344963783105,
            "max": 1.3143144605621215,
            "count": 4
        },
        "3DBall.Environment.CumulativeReward.sum": {
            "value": 651.8999724388123,
            "min": 618.3999795913696,
            "max": 651.8999724388123,
            "count": 4
        },
        "3DBall.Policy.ExtrinsicReward.mean": {
            "value": 1.3143144605621215,
            "min": 1.1734344963783105,
            "max": 1.3143144605621215,
            "count": 4
        },
        "3DBall.Policy.ExtrinsicReward.sum": {
            "value": 651.8999724388123,
            "min": 618.3999795913696,
            "max": 651.8999724388123,
            "count": 4
        },
        "3DBall.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 4
        },
        "3DBall.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 4
        },
        "3DBall.Losses.PolicyLoss.mean": {
            "value": 0.1091414280768122,
            "min": 0.1091414280768122,
            "max": 0.11087464951046712,
            "count": 2
        },
        "3DBall.Losses.PolicyLoss.sum": {
            "value": 0.1091414280768122,
            "min": 0.1091414280768122,
            "max": 0.11087464951046712,
            "count": 2
        },
        "3DBall.Losses.ValueLoss.mean": {
            "value": 0.16926621669977782,
            "min": 0.16926621669977782,
            "max": 0.18660120099795088,
            "count": 2
        },
        "3DBall.Losses.ValueLoss.sum": {
            "value": 0.16926621669977782,
            "min": 0.16926621669977782,
            "max": 0.18660120099795088,
            "count": 2
        },
        "3DBall.Policy.LearningRate.mean": {
            "value": 0.00036527120868219996,
            "min": 0.00036527120868219996,
            "max": 0.0003826384043404,
            "count": 2
        },
        "3DBall.Policy.LearningRate.sum": {
            "value": 0.00036527120868219996,
            "min": 0.00036527120868219996,
            "max": 0.0003826384043404,
            "count": 2
        },
        "3DBall.Policy.Epsilon.mean": {
            "value": 0.14565889999999998,
            "min": 0.14565889999999998,
            "max": 0.1478298,
            "count": 2
        },
        "3DBall.Policy.Epsilon.sum": {
            "value": 0.14565889999999998,
            "min": 0.14565889999999998,
            "max": 0.1478298,
            "count": 2
        },
        "3DBall.Policy.Beta.mean": {
            "value": 0.00109668182,
            "min": 0.00109668182,
            "max": 0.0011483492399999996,
            "count": 2
        },
        "3DBall.Policy.Beta.sum": {
            "value": 0.00109668182,
            "min": 0.00109668182,
            "max": 0.0011483492399999996,
            "count": 2
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1765170755",
        "python_version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\moebn\\Documents\\University\\Project 2-1\\project_2_1_group_7\\venv\\Scripts\\mlagents-learn Config/training_config.yaml --run-id=run_batch_size53_buffer_size21700_learning_rate0.0004_beta0.0012_epsilon0.15 --time-scale=20 --env=3DBall_environment/UnityEnvironment.exe --no-graphics",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.9.1+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1765170787"
    },
    "total": 31.924838800012367,
    "count": 1,
    "self": 0.21054910001112148,
    "children": {
        "run_training.setup": {
            "total": 0.0790829999896232,
            "count": 1,
            "self": 0.0790829999896232
        },
        "TrainerController.start_learning": {
            "total": 31.635206700011622,
            "count": 1,
            "self": 0.05198800057405606,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.872314999985974,
                    "count": 1,
                    "self": 6.872314999985974
                },
                "TrainerController.advance": {
                    "total": 24.704332899447763,
                    "count": 5808,
                    "self": 0.049002698506228626,
                    "children": {
                        "env_step": {
                            "total": 13.848827301117126,
                            "count": 5808,
                            "self": 12.364870200108271,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1.4486061001662165,
                                    "count": 5808,
                                    "self": 0.12386460043489933,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1.3247414997313172,
                                            "count": 4180,
                                            "self": 1.3247414997313172
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.035351000842638314,
                                    "count": 5808,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 25.337579099548748,
                                            "count": 5808,
                                            "is_parallel": true,
                                            "self": 15.992272098752437,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00022639997769147158,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 7.169993477873504e-05,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00015470004291273654,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00015470004291273654
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 9.34508060081862,
                                                    "count": 5808,
                                                    "is_parallel": true,
                                                    "self": 0.316803803172661,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 0.4887524996884167,
                                                            "count": 5808,
                                                            "is_parallel": true,
                                                            "self": 0.4887524996884167
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 7.91787669894984,
                                                            "count": 5808,
                                                            "is_parallel": true,
                                                            "self": 7.91787669894984
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 0.6216475990077015,
                                                            "count": 5808,
                                                            "is_parallel": true,
                                                            "self": 0.27215139975305647,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.34949619925464503,
                                                                    "count": 11616,
                                                                    "is_parallel": true,
                                                                    "self": 0.34949619925464503
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 10.806502899824409,
                            "count": 5808,
                            "self": 0.05855599947972223,
                            "children": {
                                "process_trajectory": {
                                    "total": 2.702541500359075,
                                    "count": 5808,
                                    "self": 2.619958900351776,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.08258260000729933,
                                            "count": 1,
                                            "self": 0.08258260000729933
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 8.045405399985611,
                                    "count": 2,
                                    "self": 3.074029699782841,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 4.9713757002027705,
                                            "count": 2454,
                                            "self": 4.9713757002027705
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.006570800003828481,
                    "count": 1,
                    "self": 1.090002479031682e-05,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.006559899979038164,
                            "count": 1,
                            "self": 0.006559899979038164
                        }
                    }
                }
            }
        }
    }
}